<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>卷积神经网络 | (๑&gt;ᴗ&lt;๑)</title><meta name="author" content="画船听雨眠y"><meta name="copyright" content="画船听雨眠y"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="写在前面 参考书籍   Aston Zhang, Zachary C. Lipton, Mu Li, Alexander J. Smola. Dive into Deep Learning. 2020. 简介 - Dive-into-DL-PyTorch (tangshusen.me) 卷积神经网络source code: NJU-ymhui&#x2F;DeepLearning: Deep Lea">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积神经网络">
<meta property="og:url" content="https://nju-ymhui.github.io/ymhui.github.io/2024/09/16/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.html">
<meta property="og:site_name" content="(๑&gt;ᴗ&lt;๑)">
<meta property="og:description" content="写在前面 参考书籍   Aston Zhang, Zachary C. Lipton, Mu Li, Alexander J. Smola. Dive into Deep Learning. 2020. 简介 - Dive-into-DL-PyTorch (tangshusen.me) 卷积神经网络source code: NJU-ymhui&#x2F;DeepLearning: Deep Lea">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://nju-ymhui.github.io/ymhui.github.io/img/myicon.ico">
<meta property="article:published_time" content="2024-09-16T14:28:32.000Z">
<meta property="article:modified_time" content="2024-09-27T07:13:38.429Z">
<meta property="article:author" content="画船听雨眠y">
<meta property="article:tag" content="pytorch">
<meta property="article:tag" content="深度学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://nju-ymhui.github.io/ymhui.github.io/img/myicon.ico"><link rel="shortcut icon" href="/ymhui.github.io/img/myicon.ico"><link rel="canonical" href="https://nju-ymhui.github.io/ymhui.github.io/2024/09/16/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/ymhui.github.io/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(()=>{
      const saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
      
      window.btf = {
        saveToLocal: saveToLocal,
        getScript: (url, attr = {}) => new Promise((resolve, reject) => {
          const script = document.createElement('script')
          script.src = url
          script.async = true
          script.onerror = reject
          script.onload = script.onreadystatechange = function() {
            const loadState = this.readyState
            if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
            script.onload = script.onreadystatechange = null
            resolve()
          }

          Object.keys(attr).forEach(key => {
            script.setAttribute(key, attr[key])
          })

          document.head.appendChild(script)
        }),

        getCSS: (url, id = false) => new Promise((resolve, reject) => {
          const link = document.createElement('link')
          link.rel = 'stylesheet'
          link.href = url
          if (id) link.id = id
          link.onerror = reject
          link.onload = link.onreadystatechange = function() {
            const loadState = this.readyState
            if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
            link.onload = link.onreadystatechange = null
            resolve()
          }
          document.head.appendChild(link)
        }),

        addGlobalFn: (key, fn, name = false, parent = window) => {
          const pjaxEnable = false
          if (!pjaxEnable && key.startsWith('pjax')) return

          const globalFn = parent.globalFn || {}
          const keyObj = globalFn[key] || {}
    
          if (name && keyObj[name]) return
    
          name = name || Object.keys(keyObj).length
          keyObj[name] = fn
          globalFn[key] = keyObj
          parent.globalFn = globalFn
        }
      }
    
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode
      
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })()</script><script>const GLOBAL_CONFIG = {
  root: '/ymhui.github.io/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '卷积神经网络',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-27 15:13:38'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/ymhui.github.io/img/myicon.ico" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><a href="/ymhui.github.io/archives/"><div class="headline">文章</div><div class="length-num">24</div></a><a href="/ymhui.github.io/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/ymhui.github.io/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/ymhui.github.io/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/ymhui.github.io/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/ymhui.github.io/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/ymhui.github.io/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/ymhui.github.io/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/ymhui.github.io/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/ymhui.github.io/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/ymhui.github.io/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/ymhui.github.io/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/ymhui.github.io/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/ymhui.github.io/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://blue-whale-backend.oss-cn-nanjing.aliyuncs.com/back.jpg);"><nav id="nav"><span id="blog-info"><a href="/ymhui.github.io/" title="(๑&gt;ᴗ&lt;๑)"><span class="site-name">(๑&gt;ᴗ&lt;๑)</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/ymhui.github.io/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/ymhui.github.io/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/ymhui.github.io/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/ymhui.github.io/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/ymhui.github.io/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/ymhui.github.io/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/ymhui.github.io/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/ymhui.github.io/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/ymhui.github.io/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/ymhui.github.io/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/ymhui.github.io/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">卷积神经网络</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-09-16T14:28:32.000Z" title="发表于 2024-09-16 22:28:32">2024-09-16</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-09-27T07:13:38.429Z" title="更新于 2024-09-27 15:13:38">2024-09-27</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="卷积神经网络"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><blockquote>
<p>参考书籍 </p>
</blockquote>
<p><a target="_blank" rel="noopener" href="http://www.d2l.ai/">Aston Zhang, Zachary C. Lipton, Mu Li, Alexander J. Smola. <em>Dive into Deep Learning</em>. 2020.</a></p>
<p><a target="_blank" rel="noopener" href="https://tangshusen.me/Dive-into-DL-PyTorch/#/">简介 - Dive-into-DL-PyTorch (tangshusen.me)</a></p>
<h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><p><strong>source code</strong>: <a target="_blank" rel="noopener" href="https://github.com/NJU-ymhui/DeepLearning">NJU-ymhui&#x2F;DeepLearning: Deep Learning with pytorch (github.com)</a></p>
<p><strong>use git to clone</strong>: <a target="_blank" rel="noopener" href="https://github.com/NJU-ymhui/DeepLearning.git">https://github.com/NJU-ymhui/DeepLearning.git</a></p>
<p><code>/CNN</code></p>
<blockquote>
<p> cross_correlation.py	fill.py	multi_pipe.py	pool_layer.py	LeNet.py</p>
</blockquote>
<h2 id="多层感知机的局限性"><a href="#多层感知机的局限性" class="headerlink" title="多层感知机的局限性"></a>多层感知机的局限性</h2><p>详见<a target="_blank" rel="noopener" href="https://d2l.ai/chapter_convolutional-neural-networks/why-conv.html#constraining-the-mlp">7.1. From Fully Connected Layers to Convolutions — Dive into Deep Learning 1.0.3 documentation (d2l.ai)</a></p>
<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>详见<a target="_blank" rel="noopener" href="https://d2l.ai/chapter_convolutional-neural-networks/why-conv.html#convolutions">7.1. From Fully Connected Layers to Convolutions — Dive into Deep Learning 1.0.3 documentation (d2l.ai)</a></p>
<h2 id="图像卷积"><a href="#图像卷积" class="headerlink" title="图像卷积"></a>图像卷积</h2><p>卷积神经网络主要用于探索图像数据，因此此处以图象为例</p>
<h3 id="互相关运算"><a href="#互相关运算" class="headerlink" title="互相关运算"></a>互相关运算</h3><p>严格地讲，卷积层是不严谨的，因为它所表达的运算实际上是<strong>互相关运算</strong>，而不是卷积运算。在这种卷积层中，输入张量和核张量通过互相关运算得到输出张量。</p>
<p>理论部分详见<a target="_blank" rel="noopener" href="https://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html#the-cross-correlation-operation">7.2. Cross-Correlation Operation — Dive into Deep Learning 1.0.3 documentation (d2l.ai)</a></p>
<blockquote>
<p>code</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d</span>(<span class="params">X, K</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算二维互相关运算&quot;&quot;&quot;</span></span><br><span class="line">    h, w = K.shape</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            Y[i, j] = (X[i:i + h, j:j + w] * K).<span class="built_in">sum</span>()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    X = torch.tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>], [<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]])</span><br><span class="line">    K = torch.tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>]])</span><br><span class="line">    <span class="built_in">print</span>(corr2d(X, K))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>output</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor([[19., 25.],</span><br><span class="line">        [37., 43.]])</span><br></pre></td></tr></table></figure>

<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>卷积层对<strong>输入和卷积核权重进行互相关运算</strong>，并在添加标量偏置之后产生输出。所以卷积层中两个被训练的参数是卷积核权重和标量偏置。因此当我们初始化参数时，要对卷积核权重进行随机初始化，同时给偏置一个初值。</p>
<blockquote>
<p>code</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Conv2D</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, kernel_size</span>):</span><br><span class="line">        <span class="comment"># kernel_size (tuple): 卷积核的大小，用于初始化权重矩阵。</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.weight = nn.Parameter(torch.rand(kernel_size))  <span class="comment"># 随机初始化权重</span></span><br><span class="line">        <span class="variable language_">self</span>.bias = nn.Parameter(torch.zeros(<span class="number">1</span>))  <span class="comment"># 为偏置赋初值</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 应用卷积操作并加上偏置项</span></span><br><span class="line">        <span class="keyword">return</span> corr2d(x, <span class="variable language_">self</span>.weight) + <span class="variable language_">self</span>.bias</span><br></pre></td></tr></table></figure>

<h3 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h3><p>下面介绍卷积层的一个简单应用：通过找到像素变化的位置，检测图像中不同颜色的边缘。</p>
<blockquote>
<p>code</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 边缘检测</span></span><br><span class="line">  	X = torch.ones((<span class="number">6</span>, <span class="number">8</span>))  <span class="comment"># 构造一个6 * 8的黑白像素图象，0黑1白</span></span><br><span class="line">   X[:, <span class="number">2</span>:<span class="number">6</span>] = <span class="number">0</span></span><br><span class="line">   <span class="built_in">print</span>(X)</span><br><span class="line">   <span class="comment"># 接下来构造一个长为1宽为2的卷积核，当相邻元素相同时，输出0</span></span><br><span class="line">   K = torch.tensor([[<span class="number">1.0</span>, -<span class="number">1.0</span>]])  <span class="comment"># [1, 0] * K = 1, [0, 1] * K = -1</span></span><br><span class="line">   <span class="comment"># 执行互相关运算</span></span><br><span class="line">   Y = corr2d(X, K)</span><br><span class="line">   <span class="comment"># 输出中1为白色到黑色的边缘, -1为黑色到白色的边缘</span></span><br><span class="line">   <span class="built_in">print</span>(Y)  <span class="comment"># 根据输出发现这种方法只能检测出垂直边缘，水平边缘消失了</span></span><br><span class="line">   <span class="comment"># 更直观的感受一下</span></span><br><span class="line">   <span class="built_in">print</span>(corr2d(X.T, K))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>output</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor([[1., 1., 0., 0., 0., 0., 1., 1.],</span><br><span class="line">        [1., 1., 0., 0., 0., 0., 1., 1.],</span><br><span class="line">        [1., 1., 0., 0., 0., 0., 1., 1.],</span><br><span class="line">        [1., 1., 0., 0., 0., 0., 1., 1.],</span><br><span class="line">        [1., 1., 0., 0., 0., 0., 1., 1.],</span><br><span class="line">        [1., 1., 0., 0., 0., 0., 1., 1.]])</span><br><span class="line">tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class="line">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class="line">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class="line">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class="line">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],</span><br><span class="line">        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])</span><br><span class="line">tensor([[0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.],</span><br><span class="line">        [0., 0., 0., 0., 0.]])</span><br></pre></td></tr></table></figure>

<h3 id="学习卷积核"><a href="#学习卷积核" class="headerlink" title="学习卷积核"></a>学习卷积核</h3><p>如果我们只需寻找黑白边缘，那么以上[1, -1]的边缘检测器足以。然而，当有了更复杂数值的卷积核，或者连续的卷积层时，我们不可能手动设计滤波器，因此考虑<strong>通过学习由X生成Y的卷积核</strong>。</p>
<p>现在我们尝试仅通过查看”输入-输出”对来学习由X生成Y的卷积核</p>
<blockquote>
<p>code</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 构造一个二维卷积层，它有1个输出通道和形状为(1, 2)的卷积核</span></span><br><span class="line">    conv2d = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=(<span class="number">1</span>, <span class="number">2</span>), bias=<span class="literal">False</span>)  <span class="comment"># 卷积核权重存在这里</span></span><br><span class="line">    <span class="comment"># 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高、宽）</span></span><br><span class="line">    <span class="comment"># 批量大小和通道都为1</span></span><br><span class="line">    X = X.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">8</span>))</span><br><span class="line">    Y = Y.reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">7</span>))</span><br><span class="line">    <span class="comment"># 准备训练</span></span><br><span class="line">    num_epochs, lr = <span class="number">10</span>, <span class="number">0.03</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;before training:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;weight:&quot;</span>, conv2d.weight.data.reshape((<span class="number">1</span>, <span class="number">2</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        Y_hat = conv2d(X)</span><br><span class="line">        l = (Y - Y_hat) ** <span class="number">2</span></span><br><span class="line">        conv2d.zero_grad()</span><br><span class="line">        l.<span class="built_in">sum</span>().backward()  <span class="comment"># 先梯度归零，再反向传播</span></span><br><span class="line">        <span class="comment"># 更新权重</span></span><br><span class="line">        conv2d.weight.data[:] -= lr * conv2d.weight.grad</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;epoch <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>, loss <span class="subst">&#123;l.<span class="built_in">sum</span>():<span class="number">.5</span>f&#125;</span>&#x27;</span>)  <span class="comment"># 可视化损失变化</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 看一下迭代后的权重如何</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;after training:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;weight:&quot;</span>, conv2d.weight.data.reshape((<span class="number">1</span>, <span class="number">2</span>)))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>output</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">before training:</span><br><span class="line">weight: tensor([[0.1613, 0.4069]])</span><br><span class="line">epoch 1, loss 19.97194</span><br><span class="line">epoch 2, loss 9.29642</span><br><span class="line">epoch 3, loss 4.52200</span><br><span class="line">epoch 4, loss 2.30929</span><br><span class="line">epoch 5, loss 1.23841</span><br><span class="line">epoch 6, loss 0.69447</span><br><span class="line">epoch 7, loss 0.40428</span><br><span class="line">epoch 8, loss 0.24228</span><br><span class="line">epoch 9, loss 0.14831</span><br><span class="line">epoch 10, loss 0.09216</span><br><span class="line">after training:</span><br><span class="line">weight: tensor([[ 1.0176, -0.9565]])</span><br></pre></td></tr></table></figure>

<h2 id="填充和步幅"><a href="#填充和步幅" class="headerlink" title="填充和步幅"></a>填充和步幅</h2><p>在应用多层卷积时，我们常常丢失边缘像素；解决这个问题的简单办法即为<strong>填充</strong>。</p>
<h3 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h3><p>原理部分详见<a target="_blank" rel="noopener" href="https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html#padding">7.3. Padding — Dive into Deep Learning 1.0.3 documentation (d2l.ai)</a></p>
<blockquote>
<p>code</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个计算卷积层的函数</span></span><br><span class="line"><span class="comment"># 为函数初始化卷积层权重，并对输入和输出提高和缩减相应的维度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">comp_conv2d</span>(<span class="params">conv2d, X</span>):</span><br><span class="line">    <span class="comment"># (1, 1)表示批量大小和通道数都是1</span></span><br><span class="line">    X = X.reshape((<span class="number">1</span>, <span class="number">1</span>) + X.shape)</span><br><span class="line">    Y = conv2d(X)</span><br><span class="line">    <span class="comment"># 省略前两个维度批量大小和通道数</span></span><br><span class="line">    <span class="keyword">return</span> Y.reshape(Y.shape[<span class="number">2</span>:])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 这里每边都填充了1行或1列，因此共添加2行或2列</span></span><br><span class="line">    conv2d = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">    X = torch.rand(size=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">    Y = comp_conv2d(conv2d, X)</span><br><span class="line">    <span class="built_in">print</span>(Y.shape)</span><br><span class="line">    conv2d = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=(<span class="number">5</span>, <span class="number">3</span>), padding=(<span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">    Y = comp_conv2d(conv2d, X)</span><br><span class="line">    <span class="built_in">print</span>(Y.shape)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>output</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.Size([8, 8])</span><br><span class="line">torch.Size([8, 8])</span><br></pre></td></tr></table></figure>

<h3 id="步幅"><a href="#步幅" class="headerlink" title="步幅"></a>步幅</h3><p><a target="_blank" rel="noopener" href="https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html#stride">7.3. Stride — Dive into Deep Learning 1.0.3 documentation (d2l.ai)</a></p>
<blockquote>
<p>code</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 步幅 2</span></span><br><span class="line">   conv2d = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">2</span>)</span><br><span class="line">   Y = comp_conv2d(conv2d, X)</span><br><span class="line">   <span class="built_in">print</span>(Y.shape)</span><br><span class="line">   conv2d = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=(<span class="number">3</span>, <span class="number">5</span>), padding=(<span class="number">0</span>, <span class="number">1</span>), stride=(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">   Y = comp_conv2d(conv2d, X)</span><br><span class="line">   <span class="built_in">print</span>(Y.shape)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>output</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">torch.Size([4, 4])</span><br><span class="line">torch.Size([2, 2])</span><br></pre></td></tr></table></figure>

<h2 id="多输入多输出通道"><a href="#多输入多输出通道" class="headerlink" title="多输入多输出通道"></a>多输入多输出通道</h2><p>之前我们一直在讨论单通道时的情况，但实际情况往往是更加复杂的。例如彩色图像往往采用<strong>标准RGB通道来代表红、绿、蓝</strong>，这就已经有<strong>三个通道</strong>了。</p>
<h3 id="多输入通道"><a href="#多输入通道" class="headerlink" title="多输入通道"></a>多输入通道</h3><p>当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，以便与输入数据进行互相关运算。</p>
<blockquote>
<p>code</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多输入</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in</span>(<span class="params">X, K</span>):</span><br><span class="line">    <span class="comment"># 先遍历X和K的第0个维度(通道维度)，再把它们加在一起</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(d2l.corr2d(x, k) <span class="keyword">for</span> x, k <span class="keyword">in</span> <span class="built_in">zip</span>(X, K))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    X = torch.tensor([[[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>], [<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]],</span><br><span class="line">                      [[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>], [<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], [<span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>]]])</span><br><span class="line">    K = torch.tensor([[[<span class="number">0.0</span>, <span class="number">1.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>]], [[<span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>]]])</span><br><span class="line">    <span class="built_in">print</span>(corr2d_multi_in(X, K))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>output</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor([[ 56.,  72.],</span><br><span class="line">        [104., 120.]])</span><br></pre></td></tr></table></figure>

<h3 id="多输出通道"><a href="#多输出通道" class="headerlink" title="多输出通道"></a>多输出通道</h3><p>目前尽管我们已经实现了多输入通道，但是输出通道还是只有一个。在当下的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。</p>
<blockquote>
<p>code</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多输入</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in</span>(<span class="params">X, K</span>):</span><br><span class="line">    <span class="comment"># 先遍历X和K的第0个维度(通道维度)，再把它们加在一起</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(d2l.corr2d(x, k) <span class="keyword">for</span> x, k <span class="keyword">in</span> <span class="built_in">zip</span>(X, K))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多输出</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in_out</span>(<span class="params">X, K</span>):</span><br><span class="line">    <span class="comment"># 遍历K的第0个维度，每次都把一个卷积层应用于X(执行互相关运算)，然后把结果收集起来</span></span><br><span class="line">    <span class="keyword">return</span> torch.stack([corr2d_multi_in(X, k) <span class="keyword">for</span> k <span class="keyword">in</span> K], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;multi in:&quot;</span>)</span><br><span class="line">    X = torch.tensor([[[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>], [<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]],</span><br><span class="line">                      [[<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>], [<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>], [<span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>]]])</span><br><span class="line">    K = torch.tensor([[[<span class="number">0.0</span>, <span class="number">1.0</span>], [<span class="number">2.0</span>, <span class="number">3.0</span>]], [[<span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>]]])</span><br><span class="line">    <span class="built_in">print</span>(corr2d_multi_in(X, K))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;multi out:&quot;</span>)</span><br><span class="line">    K = torch.stack((K, K + <span class="number">1</span>, K + <span class="number">2</span>), <span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(K.shape)</span><br><span class="line">    <span class="built_in">print</span>(corr2d_multi_in_out(X, K))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>output</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">multi in:</span><br><span class="line">tensor([[ 56.,  72.],</span><br><span class="line">        [104., 120.]])</span><br><span class="line">multi out:</span><br><span class="line">torch.Size([3, 2, 2, 2])</span><br><span class="line">tensor([[[ 56.,  72.],</span><br><span class="line">         [104., 120.]],</span><br><span class="line"></span><br><span class="line">        [[ 76., 100.],</span><br><span class="line">         [148., 172.]],</span><br><span class="line"></span><br><span class="line">        [[ 96., 128.],</span><br><span class="line">         [192., 224.]]])</span><br></pre></td></tr></table></figure>

<h3 id="1-1卷积层"><a href="#1-1卷积层" class="headerlink" title="1 * 1卷积层"></a>1 * 1卷积层</h3><p>作用详见<a target="_blank" rel="noopener" href="https://d2l.ai/chapter_convolutional-neural-networks/channels.html#times-1-convolutional-layer">7.4. Multiple Input and Multiple Output Channels — Dive into Deep Learning 1.0.3 documentation (d2l.ai)</a></p>
<blockquote>
<p>code</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多输入</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in</span>(<span class="params">X, K</span>):</span><br><span class="line">    <span class="comment"># 先遍历X和K的第0个维度(通道维度)，再把它们加在一起</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(d2l.corr2d(x, k) <span class="keyword">for</span> x, k <span class="keyword">in</span> <span class="built_in">zip</span>(X, K))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 多输出</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in_out</span>(<span class="params">X, K</span>):</span><br><span class="line">    <span class="comment"># 遍历K的第0个维度，每次都把一个卷积层应用于X(执行互相关运算)，然后把结果收集起来</span></span><br><span class="line">    <span class="keyword">return</span> torch.stack([corr2d_multi_in(X, k) <span class="keyword">for</span> k <span class="keyword">in</span> K], <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 * 1卷积</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">corr2d_multi_in_out_1x1</span>(<span class="params">X, K</span>):</span><br><span class="line">    c_i, h, w = X.shape</span><br><span class="line">    c_o = K.shape[<span class="number">0</span>]</span><br><span class="line">    X = X.reshape((c_i, h * w))</span><br><span class="line">    K = K.reshape((c_o, c_i))</span><br><span class="line">    <span class="comment"># 全连接层的矩阵乘法</span></span><br><span class="line">    Y = torch.matmul(K, X)</span><br><span class="line">    <span class="keyword">return</span> Y.reshape((c_o, h, w))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;1 * 1 correlation:&quot;</span>)</span><br><span class="line">    X = torch.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">    K = torch.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    Y1 = corr2d_multi_in_out_1x1(X, K)</span><br><span class="line">    Y2 = corr2d_multi_in_out(X, K)</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">float</span>(torch.<span class="built_in">abs</span>(Y1 - Y2).<span class="built_in">sum</span>()) &lt; <span class="number">1e-6</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">float</span>(torch.<span class="built_in">abs</span>(Y1 - Y2).<span class="built_in">sum</span>()))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>output</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1 * 1 correlation:</span><br><span class="line">0.0</span><br></pre></td></tr></table></figure>

<h2 id="汇聚层"><a href="#汇聚层" class="headerlink" title="汇聚层"></a>汇聚层</h2><p>通常当我们处理图像时，我们希望<strong>逐渐降低隐藏表示的空间分辨率、聚集信息</strong>，这样随着我们在神经网络中层叠的上升，每个神经元对其敏感的感受野（输入）就越大。</p>
<p>而机器学习任务通常会跟全局图像的问题有关（例如，“图像是否包含一只猫呢？”），所以<strong>最后一层的神经元应该对整个输入的全局敏感</strong>。<strong>通过逐渐聚合信息，生成越来越粗糙的映射，最终实现学习全局表示的目标</strong>，同时<strong>将卷积图层的所有优势保留在中间层</strong>。</p>
<p>原理部分见<a target="_blank" rel="noopener" href="https://d2l.ai/chapter_convolutional-neural-networks/pooling.html#pooling">7.5. Pooling — Dive into Deep Learning 1.0.3 documentation (d2l.ai)</a></p>
<blockquote>
<p>code</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 最大汇聚层 or 平均汇聚层</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pool2d</span>(<span class="params">X, pool_size, mode=<span class="string">&#x27;max&#x27;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;汇聚层实现，mode选择最大/平均&quot;&quot;&quot;</span></span><br><span class="line">    p_h , p_w = pool_size</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - p_h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - p_w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">&#x27;max&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">&#x27;avg&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    X = torch.tensor([[<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>], [<span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>], [<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>]])</span><br><span class="line">    <span class="built_in">print</span>(pool2d(X, (<span class="number">2</span>, <span class="number">2</span>)))  <span class="comment"># 输出最大汇聚层</span></span><br><span class="line">    <span class="built_in">print</span>(pool2d(X, (<span class="number">2</span>, <span class="number">2</span>), <span class="string">&#x27;avg&#x27;</span>))  <span class="comment"># 输出平均汇聚层</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 填充和步幅</span></span><br><span class="line">    X = torch.arange(<span class="number">16</span>, dtype=torch.float32).reshape((<span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line">    pool2d = nn.MaxPool2d(<span class="number">3</span>)</span><br><span class="line">    <span class="built_in">print</span>(pool2d(X))</span><br><span class="line">    pool2d = nn.MaxPool2d(<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(pool2d(X))</span><br><span class="line">    pool2d = nn.MaxPool2d((<span class="number">2</span>, <span class="number">3</span>), stride=(<span class="number">2</span>, <span class="number">3</span>), padding=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="built_in">print</span>(pool2d(X))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 多个通道</span></span><br><span class="line">    X = torch.cat((X, X + <span class="number">1</span>), <span class="number">1</span>)</span><br><span class="line">    pool2d = nn.MaxPool2d(<span class="number">3</span>, padding=<span class="number">1</span>, stride=<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(pool2d(X))</span><br></pre></td></tr></table></figure>

<blockquote>
<p>output</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tensor([[4., 5.],</span><br><span class="line">        [7., 8.]])</span><br><span class="line">tensor([[2., 3.],</span><br><span class="line">        [5., 6.]])</span><br><span class="line">tensor([[[[10.]]]])</span><br><span class="line">tensor([[[[ 5.,  7.],</span><br><span class="line">          [13., 15.]]]])</span><br><span class="line">tensor([[[[ 5.,  7.],</span><br><span class="line">          [13., 15.]]]])</span><br><span class="line">tensor([[[[ 5.,  7.],</span><br><span class="line">          [13., 15.]],</span><br><span class="line"></span><br><span class="line">         [[ 6.,  8.],</span><br><span class="line">          [14., 16.]]]])</span><br></pre></td></tr></table></figure>

<h2 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h2><p>到目前，我们已经掌握了构建一个完整卷积神经网络的所需组件。之前在处理Fashion-MNIST数据集时，我们使用了softmax回归和多层感知机模型，但这样需要将28 * 28的图像展平为一个784维的向量，破坏了其空间结构。而现在，通过卷积层，我们可以保留图像中的空间结构。</p>
<p><strong>LeNet</strong>是一种卷积神经网络之一，是一种监督学习。</p>
<p>主要有两部分组成：</p>
<ul>
<li>卷积编码器：由两个卷积层组成</li>
<li>全连接层密集块：由三个全连接层组成</li>
</ul>
<blockquote>
<p>code</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> d2l <span class="keyword">import</span> torch <span class="keyword">as</span> d2l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_accuracy_gpu</span>(<span class="params">net, data_iter, device=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;使用GPU计算模型在数据集上的精度&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(net, nn.Module):</span><br><span class="line">        net.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> device:</span><br><span class="line">            device = <span class="built_in">next</span>(<span class="built_in">iter</span>(net.parameters())).device</span><br><span class="line">    <span class="comment"># 准确预测的数量， 总预测的数量</span></span><br><span class="line">    metric = d2l.Accumulator(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> data_iter:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(X, <span class="built_in">list</span>):</span><br><span class="line">                <span class="comment"># Bert微调所需</span></span><br><span class="line">                X = [x.to(device) <span class="keyword">for</span> x <span class="keyword">in</span> X]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                X = X.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            metric.add(d2l.accuracy(net(X), y), y.numel())</span><br><span class="line">    <span class="keyword">return</span> metric[<span class="number">0</span>] / metric[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型，使用Xavier随机初始化模型参数，使用交叉熵损失函数和小批量随机梯度下降</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_ch6</span>(<span class="params">net, train_iter, test_iter, num_epochs, lr, device</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;使用GPU训练模型&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">m</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(m) == nn.Linear <span class="keyword">or</span> <span class="built_in">type</span>(m) == nn.Conv2d:</span><br><span class="line">            nn.init.xavier_uniform_(m.weight)</span><br><span class="line">    net.apply(init_weights)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;training on&quot;</span>, device)</span><br><span class="line">    net.to(device)</span><br><span class="line">    optimizer = torch.optim.SGD(net.parameters(), lr=lr)</span><br><span class="line">    loss = nn.CrossEntropyLoss()</span><br><span class="line">    animator = d2l.Animator(xlabel=<span class="string">&#x27;epoch&#x27;</span>, xlim=[<span class="number">1</span>, num_epochs],</span><br><span class="line">                            legend=[<span class="string">&#x27;train loss&#x27;</span>, <span class="string">&#x27;train acc&#x27;</span>, <span class="string">&#x27;test acc&#x27;</span>])</span><br><span class="line">    timer, num_batches = d2l.Timer(), <span class="built_in">len</span>(train_iter)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="comment"># 训练损失之和， 训练准确率之和， 样本数</span></span><br><span class="line">        metric = d2l.Accumulator(<span class="number">3</span>)</span><br><span class="line">        net.train()</span><br><span class="line">        <span class="keyword">for</span> i, (X, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_iter):</span><br><span class="line">            timer.start()</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            X, y = X.to(device), y.to(device)</span><br><span class="line">            y_hat = net(X)</span><br><span class="line">            l = loss(y_hat, y)</span><br><span class="line">            l.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                metric.add(l * X.shape[<span class="number">0</span>], d2l.accuracy(y_hat, y), X.shape[<span class="number">0</span>])</span><br><span class="line">            timer.stop()</span><br><span class="line">            train_l = metric[<span class="number">0</span>] / metric[<span class="number">2</span>]</span><br><span class="line">            train_acc = metric[<span class="number">1</span>] / metric[<span class="number">2</span>]</span><br><span class="line">            <span class="keyword">if</span> (i + <span class="number">1</span>) % (num_batches // <span class="number">5</span>) == <span class="number">0</span> <span class="keyword">or</span> i == num_batches - <span class="number">1</span>:</span><br><span class="line">                animator.add(epoch + (i + <span class="number">1</span>) / num_batches,</span><br><span class="line">                             (train_l, train_acc, <span class="literal">None</span>))</span><br><span class="line">        test_acc = evaluate_accuracy_gpu(net, test_iter)</span><br><span class="line">        animator.add(epoch + <span class="number">1</span>, (<span class="literal">None</span>, <span class="literal">None</span>, test_acc))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;loss <span class="subst">&#123;train_l:<span class="number">.3</span>f&#125;</span>, train acc <span class="subst">&#123;train_acc:<span class="number">.3</span>f&#125;</span>, test acc <span class="subst">&#123;test_acc:<span class="number">.3</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;metric[<span class="number">2</span>] * num_epochs / timer.<span class="built_in">sum</span>(): <span class="number">.1</span>f&#125;</span> examples/sec &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;on <span class="subst">&#123;<span class="built_in">str</span>(device)&#125;</span>&#x27;</span>)</span><br><span class="line">    d2l.plt.show()  <span class="comment"># 可视化结果</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># LeNet卷积神经网络</span></span><br><span class="line">    net = nn.Sequential(</span><br><span class="line">        nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">        nn.Sigmoid(),</span><br><span class="line">        nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">        nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">        nn.Sigmoid(),</span><br><span class="line">        nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>),</span><br><span class="line">        nn.Flatten(),</span><br><span class="line">        nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>),</span><br><span class="line">        nn.Sigmoid(),</span><br><span class="line">        nn.Linear(<span class="number">120</span>, <span class="number">84</span>),</span><br><span class="line">        nn.Sigmoid(),</span><br><span class="line">        nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">    )</span><br><span class="line">    X = torch.rand(size=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), dtype=torch.float32)</span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> net:</span><br><span class="line">        X = layer(X)</span><br><span class="line">        <span class="built_in">print</span>(layer.__class__.__name__, <span class="string">&quot;output shape: &quot;</span>, X.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 模型训练</span></span><br><span class="line">    batch_size = <span class="number">256</span></span><br><span class="line">    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)</span><br><span class="line">    lr, num_epochs = <span class="number">0.9</span>, <span class="number">10</span></span><br><span class="line">    train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())</span><br></pre></td></tr></table></figure>

<blockquote>
<p>output</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Conv2d output shape:  torch.Size([1, 6, 28, 28])</span><br><span class="line">Sigmoid output shape:  torch.Size([1, 6, 28, 28])</span><br><span class="line">AvgPool2d output shape:  torch.Size([1, 6, 14, 14])</span><br><span class="line">Conv2d output shape:  torch.Size([1, 16, 10, 10])</span><br><span class="line">Sigmoid output shape:  torch.Size([1, 16, 10, 10])</span><br><span class="line">AvgPool2d output shape:  torch.Size([1, 16, 5, 5])</span><br><span class="line">Flatten output shape:  torch.Size([1, 400])</span><br><span class="line">Linear output shape:  torch.Size([1, 120])</span><br><span class="line">Sigmoid output shape:  torch.Size([1, 120])</span><br><span class="line">Linear output shape:  torch.Size([1, 84])</span><br><span class="line">Sigmoid output shape:  torch.Size([1, 84])</span><br><span class="line">Linear output shape:  torch.Size([1, 10])</span><br><span class="line">training on cpu</span><br><span class="line">loss 0.477, train acc 0.820, test acc 0.807</span><br><span class="line"> 7299.6 examples/sec on cpu</span><br></pre></td></tr></table></figure>

<p><img src="/ymhui.github.io/2024/09/13/compare%E5%87%BD%E6%95%B0/et.png" alt="image-20240927151211020"></p>
<p>(•‿•)</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://nju-ymhui.github.io/ymhui.github.io">画船听雨眠y</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://nju-ymhui.github.io/ymhui.github.io/2024/09/16/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">https://nju-ymhui.github.io/ymhui.github.io/2024/09/16/卷积神经网络/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://nju-ymhui.github.io/ymhui.github.io" target="_blank">(๑>ᴗ<๑)</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/ymhui.github.io/tags/pytorch/">pytorch</a><a class="post-meta__tags" href="/ymhui.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div class="post-share"><div class="social-share" data-image="/ymhui.github.io/img/myicon.ico" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>真的不考虑支持一下吗 (╯︵╰,)</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/ymhui.github.io/img/qrcode.png" target="_blank"><img class="post-qr-code-img" src="/ymhui.github.io/img/qrcode.png" alt="微信支付"/></a><div class="post-qr-code-desc">微信支付</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="prev-post pull-left" href="/ymhui.github.io/2024/09/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" title="注意力机制"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">注意力机制</div></div></a><a class="next-post pull-right" href="/ymhui.github.io/2024/09/15/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/" title="多层感知机"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">多层感知机</div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a href="/ymhui.github.io/2024/09/15/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/" title="多层感知机"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-15</div><div class="title">多层感知机</div></div></a><a href="/ymhui.github.io/2024/09/15/%E7%BA%BF%E6%80%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="线性神经网络"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-15</div><div class="title">线性神经网络</div></div></a><a href="/ymhui.github.io/2024/09/16/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/" title="注意力机制"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-16</div><div class="title">注意力机制</div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info is-center"><div class="avatar-img"><img src="/ymhui.github.io/img/myicon.ico" onerror="this.onerror=null;this.src='/ymhui.github.io/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">画船听雨眠y</div><div class="author-info-description">美好的一天从打代码开始结束</div><div class="site-data"><a href="/ymhui.github.io/archives/"><div class="headline">文章</div><div class="length-num">24</div></a><a href="/ymhui.github.io/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/ymhui.github.io/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/NJU-ymhui"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/NJU-ymhui" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2"><span class="toc-number">1.</span> <span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">2.</span> <span class="toc-text">卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">2.1.</span> <span class="toc-text">多层感知机的局限性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF"><span class="toc-number">2.2.</span> <span class="toc-text">卷积</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%8D%B7%E7%A7%AF"><span class="toc-number">2.3.</span> <span class="toc-text">图像卷积</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%92%E7%9B%B8%E5%85%B3%E8%BF%90%E7%AE%97"><span class="toc-number">2.3.1.</span> <span class="toc-text">互相关运算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">2.3.2.</span> <span class="toc-text">卷积层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B"><span class="toc-number">2.3.3.</span> <span class="toc-text">边缘检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-number">2.3.4.</span> <span class="toc-text">学习卷积核</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A1%AB%E5%85%85%E5%92%8C%E6%AD%A5%E5%B9%85"><span class="toc-number">2.4.</span> <span class="toc-text">填充和步幅</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A1%AB%E5%85%85"><span class="toc-number">2.4.1.</span> <span class="toc-text">填充</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A5%E5%B9%85"><span class="toc-number">2.4.2.</span> <span class="toc-text">步幅</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E8%BE%93%E5%85%A5%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93"><span class="toc-number">2.5.</span> <span class="toc-text">多输入多输出通道</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E8%BE%93%E5%85%A5%E9%80%9A%E9%81%93"><span class="toc-number">2.5.1.</span> <span class="toc-text">多输入通道</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E8%BE%93%E5%87%BA%E9%80%9A%E9%81%93"><span class="toc-number">2.5.2.</span> <span class="toc-text">多输出通道</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1%E5%8D%B7%E7%A7%AF%E5%B1%82"><span class="toc-number">2.5.3.</span> <span class="toc-text">1 * 1卷积层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B1%87%E8%81%9A%E5%B1%82"><span class="toc-number">2.6.</span> <span class="toc-text">汇聚层</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LeNet"><span class="toc-number">2.7.</span> <span class="toc-text">LeNet</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/ymhui.github.io/2024/10/21/TSDetect/" title="TSDetect">TSDetect</a><time datetime="2024-10-21T08:48:29.000Z" title="发表于 2024-10-21 16:48:29">2024-10-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/ymhui.github.io/2024/10/01/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/" title="自然语言处理">自然语言处理</a><time datetime="2024-10-01T02:15:34.000Z" title="发表于 2024-10-01 10:15:34">2024-10-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/ymhui.github.io/2024/09/27/%E7%8E%B0%E4%BB%A3%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="现代卷积神经网络">现代卷积神经网络</a><time datetime="2024-09-27T10:54:02.000Z" title="发表于 2024-09-27 18:54:02">2024-09-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/ymhui.github.io/2024/09/23/%E7%8E%B0%E4%BB%A3%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="现代循环神经网络">现代循环神经网络</a><time datetime="2024-09-23T09:25:08.000Z" title="发表于 2024-09-23 17:25:08">2024-09-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/ymhui.github.io/2024/09/20/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="循环神经网络">循环神经网络</a><time datetime="2024-09-20T08:03:49.000Z" title="发表于 2024-09-20 16:03:49">2024-09-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2024 By 画船听雨眠y</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/ymhui.github.io/js/utils.js"></script><script src="/ymhui.github.io/js/main.js"></script><div class="js-pjax"></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>